\documentclass[11pt, reqno, oneside, letterpaper]{article}
\usepackage[small,bf]{caption}
\usepackage[utf8]{inputenc}
\usepackage[margin=0.75in]{geometry}
\usepackage{amsthm, amsmath, pstool, version}
\usepackage{amsfonts}
\usepackage{amssymb, color}
\usepackage{eucal}
\usepackage{graphicx}
\newcommand{\todo}[1]{{\color{red} TODO: {#1}}}
\renewcommand*\d{\mathop{}\!\mathrm{d}}
\graphicspath{{figs/}}
\usepackage[all]{xy}
\DeclareFontFamily{OT1}{rsfs}{}
\DeclareFontShape{OT1}{rsfs}{n}{it}{<-> rsfs10}{}
\DeclareMathAlphabet{\mathscr}{OT1}{rsfs}{n}{it}
\input defs.tex
\let\hat\widehat
\begin{document}

{\parindent 0pt
Stats 311, Winter 2018-2019 \hfill
N.\ Hirning, R.\ Pathak, J.\ Sholar \vskip 0.2in}

\begin{center}
\large{\bf Proposal}
\end{center}

In the classical empirical risk minimization setting \todo{CITE}, the goal is 
to learn some parameter $\theta$ lying in a parameter space $\Theta$, given access to 
samples $X$ lying in sample space $\mathcal{X}$, drawn according to distribution $P$. Indeed, upon receiving independently and identically distributed 
(IID) samples $X^{(1)}, X^{(2)}, \dots, X^{(n)} \sim P$, the learner minimizes the \emph{empirical loss}, 
\[
\widehat L_n(\theta) := \underset{{X \sim \hat P_n}}{\E} \ell(\theta, X) = \frac{1}{n}\sum_{i=1}^n 
\ell(\theta, X^{(i)}). 
\]
Above, $\widehat P_n := (1/n)\sum_{i=1}^n \delta_{X^{(i)}}$ denotes the \emph{empirical
distribution} of $X$, and $\ell: \Theta \times \mathcal{X} \to \R$ denotes a loss 
function. The motivation for this approach is that with population loss,
\[
L(\theta) := \underset{X \sim P}{\E} \ell(\theta, X) = \int \ell(\theta, x) \, \d P(x),
\]
the empirical loss is a good surrogate. Indeed, previous works demonstrate that under various assumptions on the 
loss function, parameter space, and samples $X$, with high probability \todo{CITE}, 
\[
L(\theta) \lesssim \hat L_n(\theta) + \sqrt{\frac{\Var(\ell(\theta, X))}{n}} + \frac{1}{n}.
\]
Notably, if $\ell$ is convex in $\theta$, for all $X$, then empirical risk minimization is also tractable.
Other authors \todo{cite} have considered augmenting this approach with an empirical variance term
(``variance-regularized empirical risk minimization''), but unfortunately this typically leads to
non-convex formulations. Recently, however, in \todo{cite Duchi}, Duchi and Namkoong present an approach
to variance-regularization that produces convex optimization problems. The main idea of the work is to use
a \emph{distributionally robust} optimization objective that preserves convexity. In particular, let $f: \R_+ \to \R$ be a convex function such that $f(1) = 0$. Additionally, consider the following uncertainty set
of distributions,
\[
\mathcal{U} = \{\text{distribution}~P \mid D_f(P \| \hat P_n) \leq \rho/n\}.  
\]
Duchi and Namkoong define a \emph{robustly regularized risk},
\[
\hat L_n(\theta, \mathcal{U}) := \sup_{P \in \mathcal{U}} \left(\underset{X \sim P}{\E} \ell(\theta, X) \right)=
\sup\left\{ \underset{X \sim P}{\E} \ell(\theta, X) : D_f(P \| \hat P_n) \leq \rho/n \right\}. 
\]
Thus, $\hat L_n(\theta, \mathcal{U})$ is convex in $\theta$ whenever $\ell$ is. The procedure suggested in
\todo{Cite duchi paper} is to pick the parameter according to
\[
\hat \theta^{\mathrm{rob}}_{n} \in \argmin_{\theta \in \Theta} \hat L_n(\theta, \mathcal{U}).
\]
Duchi and Namkoong present an efficient algorithm to compute such $\hat \theta^\mathrm{rob}_n$ \todo{CITE},
and demonstrate 
\[
\hat L_n(\theta, \mathcal{U}) = \underset{X \sim \hat P_n}{\E} \ell(\theta, X) +\sqrt{\frac{2\rho \Var_{\hat P_n}(\ell(\theta, X))}{n}} + o_{P}(1),
\]
as well as, with high probability, 
\[
L(\hat \theta^\mathrm{rob}_n) \leq \hat L_n(\hat \theta^\mathrm{rob}_n, \mathcal{U}) + C\frac{\rho}{n},
\]
where $C$ depends on $\ell$ and $\Theta$. Taken together, these demonstrate that the distributionally robut
approach outlined by Duchi and Namkoong is both tractable and a tighter approximation of the population loss
than traditional empirical risk minimization.

Our project thus picks up where \todo{cite Duchi work} leaves off. 
\end{document}
